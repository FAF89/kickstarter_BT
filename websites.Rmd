---
title: "Get Websites"
author: "Ofir Mizrahi"
date: "2018 M05 5"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("stringr")
library("sqldf")
```

##################################################################
clean the table from some inaccuracies and save as sandboxCleaned.csv
##################################################################


##Preparation

Select relevant columns.
```{r cars}
path <- "C:\\Users\\Ofir\\Desktop\\Thesis\\Kickstarter\\sandboxCleaned.csv"
temp <- read.csv(path, header = T)
temp$X <- NULL
web <- temp[,c(1,18,34)]

rm(temp,path)
```

Remove projects with no sites.
```{r}
web <- subset(web, numWebsites!=0)
```

Separate into 2 tables-
web1- has only 1 site
web2 - had more than 1 site and needs to be split into different rows
then join tables so each row is a project with one site.
```{r}
web1 <- web[web$numWebsites==1,1:2]
web2 <- web[web$numWebsites!=1,]

web2$websites <- as.character(web2$websites)
web2$url <- as.character(web2$url)
siteList <- strsplit(web2$websites, split=c(',')) #split the sites into a list
url <-c(1) 
websites <- c(1)
counter <- 1

for (i in 1:dim(web2)[1]) {
  for (j in 1:length(siteList[[i]])) {
    url[counter] <- web2[i,1]
    websites[counter] <- siteList[[i]][j]
    counter <- counter+1
  }
}

web2 <- as.data.frame(cbind(url,websites))

#join both tables together
web <- rbind(web1,web2)

rm(web1,web2,i,j,url,websites,counter,siteList)
```


Some touch-ups for easier parsing
```{r}
web$websites <- str_replace(web$websites, "http://", "")
web$websites <- str_replace(web$websites, "https://", "")
web$websites <- substr(web$websites,1,nchar(web$websites)-1)#remove last char to avoid case like "mysite.com/"

```


##Search for sites and set categories

Add columns with sites we find interesting (ignore.case = T)
```{r}

#social
web$facebook <- grepl("facebook",web$websites, ignore.case = T)
web$fb <- grepl("fb",web$websites, ignore.case = T)
web$tumblr <- grepl("tumblr",web$websites, ignore.case = T)

#business and politics
web$twitter <- grepl("twitter",web$websites, ignore.case = T)
web$linkedin <- grepl("linkedin",web$websites, ignore.case = T)
web$gitbub <- grepl("github",web$websites, ignore.case = T)


#visual (video and stiles)
web$instagram <- grepl("instagram",web$websites, ignore.case = T)
web$flickr <- grepl("flickr",web$websites, ignore.case = T)
web$youtu.be <- grepl("youtu.be",web$websites, ignore.case = T)
web$youtube <- grepl("youtube",web$websites, ignore.case = T)
web$vimeo <- grepl("vimeo",web$websites, ignore.case = T)
web$imdb <- grepl("imdb",web$websites, ignore.case = T)
web$behance <- grepl("behance",web$websites, ignore.case = T)


#music
web$soundclick <- grepl("soundclick",web$websites, ignore.case = T)
web$spotify <- grepl("spotify",web$websites, ignore.case = T)
web$itunes <- grepl("itunes",web$websites, ignore.case = T)
web$soundcloud <- grepl("soundcloud",web$websites, ignore.case = T)


#retail
web$amazon <- grepl("amazon",web$websites, ignore.case = T)
web$etsy <- grepl("etsy",web$websites, ignore.case = T)
web$ebay <- grepl("ebay",web$websites, ignore.case = T)
web$patreon <- grepl("patreon",web$websites, ignore.case = T)#it's comics, games, music.. various and they pay money
web$pinterest <- grepl("pinterest",web$websites, ignore.case = T)#usually create products


#personal sites
web$wixsite <- grepl("wixsite",web$websites, ignore.case = T)
web$wordpress <- grepl("wordpress",web$websites, ignore.case = T)
web$google <- grepl("google",web$websites, ignore.case = T)
web$wikipedia <- grepl("wikipedia",web$websites, ignore.case = T)


web$kickstarter <- grepl("kickstarter",web$websites, ignore.case = T)#we count them to ignore them. we will not group this to any category.
```


Understand the amount of projects with specific site so we know how to group them together.
```{r}
sites <- names(web)[3:ncol(web)]
amount <- vector()
for (i in 1:length(sites)) {
  amount[i] <- sum(web[,sites[i]])
}
res <- as.data.frame(cbind(sites,amount))
res$amount <- as.integer(as.character(res$amount))

rm(amount,i,sites,res)
```

Set categories and personal sites
```{r}
web$social <- web$facebook+web$fb+web$tumblr
web$business <- web$twitter+web$linkedin+web$gitbub
web$visual <- web$instagram+web$flickr+web$youtu.be+web$youtube+web$vimeo+web$imdb+web$behance
web$music <- web$soundclick+web$spotify+web$itunes+web$soundcloud
web$retail <- web$amazon+web$etsy+web$ebay+web$patreon+web$pinterest
web$personal <- web$wixsite+web$wordpress+web$google+web$wikipedia

numCategorizedSites <- web$social+web$business+web$visual+web$music+web$retail+web$personal+web$kickstarter
numCategorizedSites <- which(numCategorizedSites==0)
web[numCategorizedSites,"personal"] <- 1

rm(numCategorizedSites)
```

##Correct Inaccuracies

```{r}
#check for rows with more then 1 true value and return them to fix.
temp <- web[,c("social","business","visual","music","retail","personal")]
problem <- c()
count <- 1

for (i in 1:nrow(temp)) {
  row <- temp[i,]
  if(sum(row>0)>1){
    problem[count] <- i
    count <- count+1
  }
}

toFix1 <- web[problem,]

#check for rows with false only
problem <- c()
count <- 1
for (i in 1:nrow(temp)) {
  row <- temp[i,]
  if(sum(row)==0){
    problem[count] <- i
    count <- count+1
  }
}

toFix2 <- web[problem,]

#fixing toFix1
web["1272","social"] <- 0
web["797","social"] <- 0
web["2833","social"] <- 0
web["2821","social"] <- 0
web["6321","social"] <- 0
web["10251","social"] <- 0
web["908","personal"] <- 0
web["10861","retail"] <- 0
web["13221","retail"] <- 0
web["1323","retail"] <- 0

#fixing toFix2
web["2885","personal"] <- 1

rm(row,temp,toFix1,toFix2,count,i,problem)
```

#Final Table
Create table for attribute, will be joined with the main table.

```{r}
web <- web[,c("url", "social"   ,   "business"  ,  "visual"   ,   "music"   ,   "retail"  ,    "personal" )]

web <- sqldf("select url, sum(social) as social, sum(business) as business, sum(visual) as visual, sum(music) as music, sum(retail) as retail, sum(personal) as personal
             from web
             group by url")

path <- "C:\\Users\\Ofir\\Desktop\\Thesis\\Kickstarter\\web.csv"
write.csv(web, path)

web$social <- ifelse(web$social>0,1,0)
web$business <- ifelse(web$business>0,1,0)
web$visual <- ifelse(web$visual>0,1,0)
web$music <- ifelse(web$music>0,1,0)
web$retail <- ifelse(web$retail>0,1,0)
web$personal <- ifelse(web$personal>0,1,0)

path <- "C:\\Users\\Ofir\\Desktop\\Thesis\\Kickstarter\\webBinary.csv"
write.csv(web, path)

```

